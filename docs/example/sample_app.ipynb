{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamsx==1.16.0b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamsx.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show streamsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import streamsx.endpoint as endpoint\n",
    "\n",
    "from streamsx import rest\n",
    "from streamsx.topology.topology import Topology\n",
    "from streamsx.topology.schema import CommonSchema\n",
    "from streamsx.topology.context import submit, ContextTypes\n",
    "from streamsx.rest_primitives import Instance\n",
    "from streamsx.topology import context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callable source \n",
    "class SensorReadingsSource(object):\n",
    "    def __call__(self):\n",
    "        # This is just an example of using generated data, \n",
    "        # Here you could connect to db\n",
    "        # generate data\n",
    "        # connect to data set\n",
    "        # open file\n",
    "        while True:\n",
    "            time.sleep(0.001)\n",
    "            sensor_id = random.randint(1,100)\n",
    "            reading = {}\n",
    "            reading [\"sensor_id\"] = \"sensor_\" + str(sensor_id)\n",
    "            reading [\"value\"] =  random.random() * 3000\n",
    "            reading[\"ts\"] = int((datetime.now().timestamp())) \n",
    "            yield reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_reading(items_in_window):\n",
    "    df = pd.DataFrame(items_in_window)\n",
    "    readings_by_id = df.groupby(\"sensor_id\")\n",
    "    \n",
    "    averages = readings_by_id[\"value\"].mean()\n",
    "    period_end = df[\"ts\"].max()\n",
    "\n",
    "    result = []\n",
    "    for id, avg in averages.iteritems():\n",
    "        result.append({\"average\": avg,\n",
    "                \"sensor_id\": id,\n",
    "                \"period_end\": time.ctime(period_end)})\n",
    "               \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the original tuple with a new `coords` attribute\n",
    "# representing the latitude and longitude of the sensor\n",
    "def enrich(tpl):\n",
    "    # use simulated data, but you could make a database call, \n",
    "    lat = round(random.random() + 39.8338515, 4)\n",
    "    lon = round(-74.871826 + random.random(), 4)\n",
    "    # update the tuple with new data\n",
    "    tpl[\"coords\"] = (lat, lon)\n",
    "    return tpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build and submit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topo():\n",
    "    \n",
    "    # Build Graph\n",
    "    topo = Topology(name=\"SensorAverages\")\n",
    "    \n",
    "    #Create a stream from the data using Topology.source\n",
    "    readings = topo.source(SensorReadingsSource(), name=\"Readings\")\n",
    "    \n",
    "    valid_readings = readings.filter(lambda x : x[\"value\"] > 100,\n",
    "                                 name=\"ValidReadings\")\n",
    "    \n",
    "    # 2. Define window: e.g. a 30 second rolling average, updated every second\n",
    "    interval = timedelta(seconds=30)\n",
    "    window = valid_readings.last(size=interval).trigger(when=timedelta(seconds=1))\n",
    "\n",
    "    # 3. Pass aggregation function to Window.aggregate\n",
    "    # average_reading returns a list of the averages for each sensor,\n",
    "    # use flat map to convert it to individual tuples, one per sensor\n",
    "    rolling_average = window.aggregate(average_reading).flat_map()\n",
    "    \n",
    "    # Update the data on the rolling_average stream with the map transform\n",
    "    enriched_average = rolling_average.map(enrich).as_json()\n",
    "    \n",
    "    endpoint.expose(window=enriched_average.last(1).trigger(1),\n",
    "                context='sensor-averages',\n",
    "                name='enriched',\n",
    "                monitor=None)\n",
    "    \n",
    "    return topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_topology(topo):\n",
    "    \n",
    "    # Set the following 4 lines\n",
    "    CP4D_URL = \"...\"\n",
    "    STREAMS_INSTANCE_NAME = \"...\"\n",
    "    STREAMS_USERNAME = '...'\n",
    "    STREAMS_PASSWORD = '...'\n",
    "    \n",
    "    os.environ[\"STREAMS_USERNAME\"] = STREAMS_USERNAME\n",
    "    os.environ[\"STREAMS_PASSWORD\"] = STREAMS_PASSWORD\n",
    "    os.environ[\"STREAMS_INSTANCE_ID\"] = STREAMS_INSTANCE_NAME\n",
    "    os.environ[\"CP4D_URL\"] = CP4D_URL\n",
    "\n",
    "    cfg ={}\n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = False\n",
    "    # This specifies how the application will be deployed\n",
    "    contextType = context.ContextTypes.DISTRIBUTED\n",
    "    return context.submit (contextType, topo, config = cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = build_topo()\n",
    "\n",
    "print(\"Submitting Topology to Streams for execution..\")\n",
    "submission_result = submit_topology(topo)\n",
    "\n",
    "if submission_result.job:\n",
    "  streams_job = submission_result.job\n",
    "  print (\"JobId: \", streams_job.id , \"\\nJob name: \", streams_job.name)\n",
    "else:\n",
    "  print(\"Submission failed: \"   + str(submission_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Connect to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = '...'\n",
    "\n",
    "endpoint_url = 'https://' + hostname + '/streams/jobs/' + streams_job.id + '/sensor-averages/enriched/tuples'\n",
    "print(endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Display the results in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    source = requests.get(endpoint_url, verify=False).json()\n",
    "    print(source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
